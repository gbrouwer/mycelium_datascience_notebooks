{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import imageio\n",
    "import pickle\n",
    "import json\n",
    "import visualkeras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Dense, Flatten\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csfont = {'fontname':'Georgia'}\n",
    "hfont = {'fontname':'Helvetica'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = []\n",
    "classnames = []\n",
    "codedict = {}\n",
    "classdict = {}\n",
    "labeldict = {}\n",
    "ydict = {}\n",
    "classcode = -1\n",
    "with open('../../data/imagenet/meta/100_categories','r') as f:\n",
    "    for line in f:\n",
    "        elements = line.rstrip().split(':')\n",
    "        code = elements[0]\n",
    "        codes.append(code)\n",
    "        classname = elements[1].replace(\"'\",\"\")\n",
    "        classname = classname.split(',')[0][1:].lower()\n",
    "        classnames.append(classname)\n",
    "        if (classname not in labeldict):\n",
    "            classcode = classcode + 1\n",
    "            labeldict[classname] = classcode\n",
    "            ydict[classcode] = classname\n",
    "        codedict[code] = classname\n",
    "        classdict[classname] = code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image,label):\n",
    "    image=tf.image.per_image_standardization(image)\n",
    "    image=tf.image.resize(image,(227,227))\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation\n",
    "\n",
    "Within this section, we will implement the AlexNet CNN architecture from scratch. Through the utilization of Keras Sequential API, we can implement consecutive neural network layers within our models that are stacked against each other. Here are the types of layers the AlexNet CNN architecture is composed of, along with a brief description:\n",
    "\n",
    "<b>Convolutional layer</b>. A convolution is a mathematical term that describes a dot product multiplication between two sets of elements. Within deep learning the convolution operation acts on the filters/kernels and image data array within the convolutional layer. Therefore a convolutional layer is simply a layer the houses the convolution operation that occurs between the filters and the images passed through a convolutional neural network.\n",
    "\n",
    "<b>Batch Normalisation layer</b>. Batch Normalization is a technique that mitigates the effect of unstable gradients within a neural network through the introduction of an additional layer that performs operations on the inputs from the previous layer. The operations standardize and normalize the input values, after that the input values are transformed through scaling and shifting operations.\n",
    "\n",
    "<b>MaxPooling layer</b>. Max pooling is a variant of sub-sampling where the maximum pixel value of pixels that fall within the receptive field of a unit within a sub-sampling layer is taken as the output. The max-pooling operation below has a window of 2x2 and slides across the input data, outputting an average of the pixels within the receptive field of the kernel.\n",
    "\n",
    "<b>Flatten layer</b>. Takes an input shape and flattens the input image data into a one-dimensional array.\n",
    "\n",
    "<b>Dense Layer</b>. A dense layer has an embedded number of arbitrary units/neurons within. Each neuron is a perceptron. The code snippet represents the Keras implementation of the AlexNet CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential([\n",
    "    \n",
    "    #Conv1\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    \n",
    "    #Conv2\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    \n",
    "    #Conv3\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    #Conv4\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    #Conv5\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100,activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10552, 240, 240, 3)\n",
      "Epoch 1/10\n",
      "263/263 [==============================] - 312s 1s/step - loss: 6.3649 - accuracy: 0.0191 - val_loss: 4.5158 - val_accuracy: 0.0365\n",
      "Epoch 2/10\n",
      "263/263 [==============================] - 320s 1s/step - loss: 4.7197 - accuracy: 0.0297 - val_loss: 4.4899 - val_accuracy: 0.0413\n",
      "Epoch 3/10\n",
      "263/263 [==============================] - 276s 1s/step - loss: 4.6090 - accuracy: 0.0289 - val_loss: 4.4661 - val_accuracy: 0.0375\n",
      "Epoch 4/10\n",
      "263/263 [==============================] - 267s 1000ms/step - loss: 4.5260 - accuracy: 0.0377 - val_loss: 4.3343 - val_accuracy: 0.0413\n",
      "Epoch 5/10\n",
      "263/263 [==============================] - 256s 961ms/step - loss: 4.5009 - accuracy: 0.0361 - val_loss: 4.3881 - val_accuracy: 0.0356\n",
      "Epoch 6/10\n",
      "263/263 [==============================] - 267s 1s/step - loss: 4.4623 - accuracy: 0.0351 - val_loss: 4.3181 - val_accuracy: 0.0380\n",
      "Epoch 7/10\n",
      "263/263 [==============================] - 288s 1s/step - loss: 4.4143 - accuracy: 0.0372 - val_loss: 4.2472 - val_accuracy: 0.0510\n",
      "Epoch 8/10\n",
      "263/263 [==============================] - 283s 1s/step - loss: 4.3905 - accuracy: 0.0384 - val_loss: 4.2394 - val_accuracy: 0.0481\n",
      "Epoch 9/10\n",
      "263/263 [==============================] - 249s 923ms/step - loss: 4.3739 - accuracy: 0.0424 - val_loss: 4.1995 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "154/263 [================>.............] - ETA: 1:38 - loss: 4.3256 - accuracy: 0.0428"
     ]
    }
   ],
   "source": [
    "for i in range(0,20,4):\n",
    "    \n",
    "    #Load\n",
    "    data1 = pickle.load( open(\"../../data/imagenet/pickle/train/\" + str(i+0) + \".p\", \"rb\"))\n",
    "    data2 = pickle.load( open(\"../../data/imagenet/pickle/train/\" + str(i+1) + \".p\", \"rb\"))\n",
    "    data3 = pickle.load( open(\"../../data/imagenet/pickle/train/\" + str(i+2) + \".p\", \"rb\"))\n",
    "    data4 = pickle.load( open(\"../../data/imagenet/pickle/train/\" + str(i+3) + \".p\", \"rb\"))\n",
    "\n",
    "    #Unpack\n",
    "    y1 = data1['y']\n",
    "    y2 = data2['y']\n",
    "    y3 = data3['y']\n",
    "    y4 = data4['y']\n",
    "    y1 = np.expand_dims(y1,-1)\n",
    "    y2 = np.expand_dims(y2,-1)\n",
    "    y3 = np.expand_dims(y3,-1)\n",
    "    y4 = np.expand_dims(y4,-1)\n",
    "    y1_labels = data1['y_labels']\n",
    "    y2_labels = data2['y_labels']\n",
    "    y3_labels = data3['y_labels']\n",
    "    y4_labels = data4['y_labels']\n",
    "    images1 = data1['images']\n",
    "    images2 = data2['images']\n",
    "    images3 = data3['images']\n",
    "    images4 = data4['images']\n",
    "\n",
    "    #Combine\n",
    "    images = np.vstack((images1,images2,images3,images4))\n",
    "    y = np.vstack((y1,y2,y3,y4))\n",
    "    y_labels = np.hstack((y1_labels,y2_labels,y3_labels,y4_labels))\n",
    "    print(images.shape)\n",
    "\n",
    "    #Divide\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(images, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    #To Tensorflow\n",
    "    train_ds=tf.data.Dataset.from_tensor_slices((train_images,train_labels))\n",
    "    test_ds=tf.data.Dataset.from_tensor_slices((test_images,test_labels))\n",
    "    train_ds_size=tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    test_ds_size=tf.data.experimental.cardinality(test_ds).numpy()\n",
    "    train_ds=(train_ds\n",
    "              .map(process_image)\n",
    "              .shuffle(buffer_size=train_ds_size)\n",
    "              .batch(batch_size=32,drop_remainder=True))\n",
    "    test_ds=(test_ds\n",
    "             .map(process_image)\n",
    "             .shuffle(buffer_size=test_ds_size)\n",
    "             .batch(batch_size=32,drop_remainder=True))\n",
    "    \n",
    "    history=model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds,\n",
    "    validation_freq=1)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,1,figsize=(10,10)) \n",
    "\n",
    "#Assigning the first subplot to graph training loss and validation loss\n",
    "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Plotting the training accuracy and validation accuracy\n",
    "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score = ',np.max(history.history['val_accuracy']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
