{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d23ed4",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15cc116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from __future__ import print_function\n",
    "#from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e502a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec6d6567",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "619c4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4924f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   ==========\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
      "fetching / caching functions that downloads the data archive from\n",
      "the original `20 newsgroups website`_, extracts the archive contents\n",
      "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
      ":func:`sklearn.datasets.load_files` on either the training or\n",
      "testing set folder, or both of them::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_20newsgroups\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
      "\n",
      "  >>> from pprint import pprint\n",
      "  >>> pprint(list(newsgroups_train.target_names))\n",
      "  ['alt.atheism',\n",
      "   'comp.graphics',\n",
      "   'comp.os.ms-windows.misc',\n",
      "   'comp.sys.ibm.pc.hardware',\n",
      "   'comp.sys.mac.hardware',\n",
      "   'comp.windows.x',\n",
      "   'misc.forsale',\n",
      "   'rec.autos',\n",
      "   'rec.motorcycles',\n",
      "   'rec.sport.baseball',\n",
      "   'rec.sport.hockey',\n",
      "   'sci.crypt',\n",
      "   'sci.electronics',\n",
      "   'sci.med',\n",
      "   'sci.space',\n",
      "   'soc.religion.christian',\n",
      "   'talk.politics.guns',\n",
      "   'talk.politics.mideast',\n",
      "   'talk.politics.misc',\n",
      "   'talk.religion.misc']\n",
      "\n",
      "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
      "attribute is the integer index of the category::\n",
      "\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
      "\n",
      "It is possible to load only a sub-selection of the categories by passing the\n",
      "list of the categories to load to the\n",
      ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
      "\n",
      "  >>> cats = ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      "\n",
      "  >>> list(newsgroups_train.target_names)\n",
      "  ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      "Converting text to vectors\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "In order to feed predictive or clustering models with the text data,\n",
      "one first need to turn the text into vectors of numerical values suitable\n",
      "for statistical analysis. This can be achieved with the utilities of the\n",
      "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
      "example that extract `TF-IDF`_ vectors of unigram tokens\n",
      "from a subset of 20news::\n",
      "\n",
      "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
      "  ...               'comp.graphics', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectorizer = TfidfVectorizer()\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> vectors.shape\n",
      "  (2034, 34118)\n",
      "\n",
      "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
      "components by sample in a more than 30000-dimensional space\n",
      "(less than .5% non-zero features)::\n",
      "\n",
      "  >>> vectors.nnz / float(vectors.shape[0])\n",
      "  159.01327...\n",
      "\n",
      ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
      "returns ready-to-use token counts features instead of file names.\n",
      "\n",
      ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
      ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
      "\n",
      "\n",
      "Filtering text for more realistic training\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "It is easy for a classifier to overfit on particular things that appear in the\n",
      "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
      "high F-scores, but their results would not generalize to other documents that\n",
      "aren't from this window of time.\n",
      "\n",
      "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
      "which is fast to train and achieves a decent F-score::\n",
      "\n",
      "  >>> from sklearn.naive_bayes import MultinomialNB\n",
      "  >>> from sklearn import metrics\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "  0.88213...\n",
      "\n",
      "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
      "the training and test data, instead of segmenting by time, and in that case\n",
      "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
      "yet of what's going on inside this classifier?)\n",
      "\n",
      "Let's take a look at what the most informative features are:\n",
      "\n",
      "  >>> import numpy as np\n",
      "  >>> def show_top10(classifier, vectorizer, categories):\n",
      "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "  ...     for i, category in enumerate(categories):\n",
      "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
      "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
      "  ...\n",
      "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
      "  alt.atheism: edu it and in you that is of to the\n",
      "  comp.graphics: edu in graphics it is for and of to the\n",
      "  sci.space: edu it that is in and space to of the\n",
      "  talk.religion.misc: not it you in is that and to of the\n",
      "\n",
      "\n",
      "You can now see many things that these features have overfit to:\n",
      "\n",
      "- Almost every group is distinguished by whether headers such as\n",
      "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
      "- Another significant feature involves whether the sender is affiliated with\n",
      "  a university, as indicated either by their headers or their signature.\n",
      "- The word \"article\" is a significant feature, based on how often people quote\n",
      "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
      "  wrote:\"\n",
      "- Other features match the names and e-mail addresses of particular people who\n",
      "  were posting at the time.\n",
      "\n",
      "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
      "barely have to identify topics from text at all, and they all perform at the\n",
      "same high level.\n",
      "\n",
      "For this reason, the functions that load 20 Newsgroups data provide a\n",
      "parameter called **remove**, telling it what kinds of information to strip out\n",
      "of each file. **remove** should be a tuple containing any subset of\n",
      "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
      "blocks, and quotation blocks respectively.\n",
      "\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
      "  0.77310...\n",
      "\n",
      "This classifier lost over a lot of its F-score, just because we removed\n",
      "metadata that has little to do with topic classification.\n",
      "It loses even more if we also strip this metadata from the training data:\n",
      "\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "  0.76995...\n",
      "\n",
      "Some other classifiers cope better with this harder version of the task. Try\n",
      "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
      "the ``--filter`` option to compare the results.\n",
      "\n",
      ".. topic:: Recommendation\n",
      "\n",
      "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
      "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
      "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
      "  lower because it is more realistic.\n",
      "\n",
      ".. topic:: Examples\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
      "\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'From: nigel.allen@canrem.com (Nigel Allen)\\nSubject: library of congress to host dead sea scroll symposium april 21-22\\nLines: 96\\n\\n\\n Library of Congress to Host Dead Sea Scroll Symposium April 21-22\\n To: National and Assignment desks, Daybook Editor\\n Contact: John Sullivan, 202-707-9216, or Lucy Suddreth, 202-707-9191\\n          both of the Library of Congress\\n\\n   WASHINGTON, April 19  -- A symposium on the Dead Sea \\nScrolls will be held at the Library of Congress on Wednesday,\\nApril 21, and Thursday, April 22.  The two-day program, cosponsored\\nby the library and Baltimore Hebrew University, with additional\\nsupport from the Project Judaica Foundation, will be held in the\\nlibrary\\'s Mumford Room, sixth floor, Madison Building.\\n   Seating is limited, and admission to any session of the symposium\\nmust be requested in writing (see Note A).\\n   The symposium will be held one week before the public opening of a\\nmajor exhibition, \"Scrolls from the Dead Sea: The Ancient Library of\\nQumran and Modern Scholarship,\" that opens at the Library of Congress\\non April 29.  On view will be fragmentary scrolls and archaeological\\nartifacts excavated at Qumran, on loan from the Israel Antiquities\\nAuthority.  Approximately 50 items from Library of Congress special\\ncollections will augment these materials.  The exhibition, on view in\\nthe Madison Gallery, through Aug. 1, is made possible by a generous\\ngift from the Project Judaica Foundation of Washington, D.C.\\n   The Dead Sea Scrolls have been the focus of public and scholarly\\ninterest since 1947, when they were discovered in the desert 13 miles\\neast of Jerusalem.  The symposium will explore the origin and meaning\\nof the scrolls and current scholarship.  Scholars from diverse\\nacademic backgrounds and religious affiliations, will offer their\\ndisparate views, ensuring a lively discussion.\\n   The symposium schedule includes opening remarks on April 21, at\\n2 p.m., by Librarian of Congress James H. Billington, and by\\nDr. Norma Furst, president, Baltimore Hebrew University.  Co-chairing\\nthe symposium are Joseph Baumgarten, professor of Rabbinic Literature\\nand Institutions, Baltimore Hebrew University and Michael Grunberger,\\nhead, Hebraic Section, Library of Congress.\\n   Geza Vermes, professor emeritus of Jewish studies, Oxford\\nUniversity, will give the keynote address on the current state of\\nscroll research, focusing on where we stand today. On the second\\nday, the closing address will be given by Shmaryahu Talmon, who will\\npropose a research agenda, picking up the theme of how the Qumran\\nstudies might proceed.\\n   On Wednesday, April 21, other speakers will include:\\n\\n   -- Eugene Ulrich, professor of Hebrew Scriptures, University of\\nNotre Dame and chief editor, Biblical Scrolls from Qumran, on \"The\\nBible at Qumran;\"\\n   -- Michael Stone, National Endowment for the Humanities\\ndistinguished visiting professor of religious studies, University of\\nRichmond, on \"The Dead Sea Scrolls and the Pseudepigrapha.\"\\n   -- From 5 p.m. to 6:30 p.m. a special preview of the exhibition\\nwill be given to symposium participants and guests.\\n\\n   On Thursday, April 22, beginning at 9 a.m., speakers will include:\\n\\n   -- Magen Broshi, curator, shrine of the Book, Israel Museum,\\nJerusalem, on \"Qumran: The Archaeological Evidence;\"\\n   -- P. Kyle McCarter, Albright professor of Biblical and ancient\\nnear Eastern studies, The Johns Hopkins University, on \"The Copper\\nScroll;\"\\n   -- Lawrence H. Schiffman, professor of Hebrew and Judaic studies,\\nNew York University, on \"The Dead Sea Scrolls and the History of\\nJudaism;\" and\\n   -- James VanderKam, professor of theology, University of Notre\\nDame, on \"Messianism in the Scrolls and in Early Christianity.\"\\n\\n   The Thursday afternoon sessions, at 1:30 p.m., include:\\n\\n   -- Devorah Dimant, associate professor of Bible and Ancient Jewish\\nThought, University of Haifa, on \"Qumran Manuscripts: Library of a\\nJewish Community;\"\\n   -- Norman Golb, Rosenberger professor of Jewish history and\\ncivilization, Oriental Institute, University of Chicago, on \"The\\nCurrent Status of the Jerusalem Origin of the Scrolls;\"\\n   -- Shmaryahu Talmon, J.L. Magnas professor emeritus of Biblical\\nstudies, Hebrew University, Jerusalem, on \"The Essential \\'Commune of\\nthe Renewed Covenant\\': How Should Qumran Studies Proceed?\" will close\\nthe symposium.\\n\\n   There will be ample time for question and answer periods at the\\nend of each session.\\n\\n   Also on Wednesday, April 21, at 11 a.m.:\\n   The Library of Congress and The Israel Antiquities Authority\\nwill hold a lecture by Esther Boyd-Alkalay, consulting conservator,\\nIsrael Antiquities Authority, on \"Preserving the Dead Sea Scrolls\"\\nin the Mumford Room, LM-649, James Madison Memorial Building, The\\nLibrary of Congress, 101 Independence Ave., S.E., Washington, D.C.\\n    ------\\n   NOTE A: For more information about admission to the symposium,\\nplease contact, in writing, Dr. Michael Grunberger, head, Hebraic\\nSection, African and Middle Eastern Division, Library of Congress,\\nWashington, D.C. 20540.\\n -30-\\n--\\nCanada Remote Systems - Toronto, Ontario\\n416-629-7000/629-7044\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#newsgroups_train['target'][1]\n",
    "print(newsgroups_train['DESCR'])\n",
    "print('-----')\n",
    "newsgroups_train['data'][0]\n",
    "#newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60074714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "# train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "# test_vectors = vectorizer.transform(newsgroups_test.data)\n",
    "# Now, let's say we want to use random forests for classification. It's usually hard to understand what random forests are doing, especially with many trees.\n",
    "\n",
    "# rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "# rf.fit(train_vectors, newsgroups_train.target)\n",
    "# RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "#             oob_score=False, random_state=None, verbose=0,\n",
    "#             warm_start=False)\n",
    "# pred = rf.predict(test_vectors)\n",
    "# sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary')\n",
    "# 0.92093023255813955\n",
    "# We see that this classifier achieves a very high F score. The sklearn guide to 20 newsgroups indicates that Multinomial Naive Bayes overfits this dataset by learning irrelevant stuff, such as headers. Let's see if random forests do the same.\n",
    "\n",
    "# Explaining predictions using lime\n",
    "# Lime explainers assume that classifiers act on raw text, but sklearn classifiers act on vectorized representation of texts. For this purpose, we use sklearn's pipeline, and implements predict_proba on raw_text lists.\n",
    "\n",
    "# from lime import lime_text\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# c = make_pipeline(vectorizer, rf)\n",
    "# print(c.predict_proba([newsgroups_test.data[0]]))\n",
    "# [[ 0.274  0.726]]\n",
    "# Now we create an explainer object. We pass the class_names a an argument for prettier display.\n",
    "\n",
    "# from lime.lime_text import LimeTextExplainer\n",
    "# explainer = LimeTextExplainer(class_names=class_names)\n",
    "# We then generate an explanation with at most 6 features for an arbitrary document in the test set.\n",
    "\n",
    "# idx = 83\n",
    "# exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
    "# print('Document id: %d' % idx)\n",
    "# print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
    "# print('True class: %s' % class_names[newsgroups_test.target[idx]])\n",
    "# Document id: 83\n",
    "# Probability(christian) = 0.414\n",
    "# True class: atheism\n",
    "# The classifier got this example right (it predicted atheism).\n",
    "# The explanation is presented below as a list of weighted features.\n",
    "\n",
    "# exp.as_list()\n",
    "# [(u'Posting', -0.15748303818990594),\n",
    "#  (u'Host', -0.13220892468795911),\n",
    "#  (u'NNTP', -0.097422972255878093),\n",
    "#  (u'edu', -0.051080418945152584),\n",
    "#  (u'have', -0.010616558305370854),\n",
    "#  (u'There', -0.0099743822272458232)]\n",
    "# These weighted features are a linear model, which approximates the behaviour of the random forest classifier in the vicinity of the test example. Roughly, if we remove 'Posting' and 'Host' from the document , the prediction should move towards the opposite class (Christianity) by about 0.27 (the sum of the weights for both features). Let's see if this is the case.\n",
    "\n",
    "# print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n",
    "# tmp = test_vectors[idx].copy()\n",
    "# tmp[0,vectorizer.vocabulary_['Posting']] = 0\n",
    "# tmp[0,vectorizer.vocabulary_['Host']] = 0\n",
    "# print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n",
    "# print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])\n",
    "# Original prediction: 0.414\n",
    "# Prediction removing some features: 0.684\n",
    "# Difference: 0.27\n",
    "# Pretty close!\n",
    "# The words that explain the model around this document seem very arbitrary - not much to do with either Christianity or Atheism.\n",
    "# In fact, these are words that appear in the email headers (you will see this clearly soon), which make distinguishing between the classes much easier.\n",
    "\n",
    "# Visualizing explanations\n",
    "# The explanations can be returned as a matplotlib barplot:\n",
    "\n",
    "# %matplotlib inline\n",
    "# fig = exp.as_pyplot_figure()\n",
    "\n",
    "# The explanations can also be exported as an html page (which we can render here in this notebook), using D3.js to render graphs.\n",
    "\n",
    "# exp.show_in_notebook(text=False)\n",
    "# Prediction probabilities\n",
    "# 0.59\n",
    "# atheism\n",
    "# 0.41\n",
    "# christian\n",
    "# atheism\n",
    "# christian\n",
    "# Posting\n",
    "# 0.16\n",
    "# Host\n",
    "# 0.13\n",
    "# NNTP\n",
    "# 0.10\n",
    "# edu\n",
    "# 0.05\n",
    "# have\n",
    "# 0.01\n",
    "# There\n",
    "# 0.01\n",
    "# Alternatively, we can save the fully contained html page to a file:\n",
    "\n",
    "# exp.save_to_file('/tmp/oi.html')\n",
    "# Finally, we can also include a visualization of the original document, with the words in the explanations highlighted. Notice how the words that affect the classifier the most are all in the email header.\n",
    "\n",
    "# exp.show_in_notebook(text=True)\n",
    "# Prediction probabilities\n",
    "# 0.59\n",
    "# atheism\n",
    "# 0.41\n",
    "# christian\n",
    "# atheism\n",
    "# christian\n",
    "# Posting\n",
    "# 0.16\n",
    "# Host\n",
    "# 0.13\n",
    "# NNTP\n",
    "# 0.10\n",
    "# edu\n",
    "# 0.05\n",
    "# have\n",
    "# 0.01\n",
    "# There\n",
    "# 0.01\n",
    "# Text with highlighted words\n",
    "# From: johnchad@triton.unm.edu (jchadwic)\n",
    "# Subject: Another request for Darwin Fish\n",
    "# Organization: University of New Mexico, Albuquerque\n",
    "# Lines: 11\n",
    "# NNTP-Posting-Host: triton.unm.edu\n",
    "\n",
    "# Hello Gang,\n",
    "\n",
    "# There have been some notes recently asking where to obtain the DARWIN fish.\n",
    "# This is the same question I have and I have not seen an answer on the\n",
    "# net. If anyone has a contact please post on the net or email me.\n",
    "\n",
    "# Thanks,\n",
    "\n",
    "# john chadwick\n",
    "# johnchad@triton.unm.edu\n",
    "# or\n",
    "# That's it for this tutorial. Random forests were just an example, this explainer works for any classifier you may want to use, as long as it implements predict_proba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
