{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3117a1ea",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15cc116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cccdc2",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "563f9de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"../../data/cancer_corpi/articles/pickle/processed.p\",\"rb\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341c56d",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "480ea4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "y_names = []\n",
    "X = []\n",
    "for item in data['records']:\n",
    "    label = item[-1]\n",
    "    y_names.append(label)\n",
    "    X.append(item[0])\n",
    "X = np.expand_dims(np.array(X),-1)\n",
    "y_names = np.expand_dims(np.array(y_names),-1)\n",
    "classes = np.unique(y_names)\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(y_names)\n",
    "y = enc.transform(y_names).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6c59c",
   "metadata": {},
   "source": [
    "### Count examples for class and restrict to 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3833427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.sum(y,axis=0)\n",
    "idx1 = np.where(y_names == 'breast_cancer')[0]\n",
    "idx2 = np.where(y_names == 'leukemia')[0]\n",
    "mincount = np.min([len(idx1),len(idx2)])\n",
    "idx1 = idx1[:mincount]\n",
    "idx2 = idx2[:mincount]\n",
    "idx = np.union1d(idx1,idx2)\n",
    "randperm = np.random.permutation(len(idx))\n",
    "idx = idx[randperm]\n",
    "X = X[idx,:]\n",
    "y = y[idx,:]\n",
    "y = y[:,[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05702c",
   "metadata": {},
   "source": [
    "### Divide into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5fed7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5ce77",
   "metadata": {},
   "source": [
    "### Get the vocabulary and vectorize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a58277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=True,stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(X_train[:,0])\n",
    "test_vectors = vectorizer.transform(X_test[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dccb85",
   "metadata": {},
   "source": [
    "### Create Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0700665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500);\n",
    "rf.fit(train_vectors, y_train);\n",
    "# RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "#             oob_score=False, random_state=None, verbose=0,\n",
    "#             warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "# train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "# test_vectors = vectorizer.transform(newsgroups_test.data)\n",
    "# Now, let's say we want to use random forests for classification. It's usually hard to understand what random forests are doing, especially with many trees.\n",
    "\n",
    "# rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "# rf.fit(train_vectors, newsgroups_train.target)\n",
    "# RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "#             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "#             min_samples_leaf=1, min_samples_split=2,\n",
    "#             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "#             oob_score=False, random_state=None, verbose=0,\n",
    "#             warm_start=False)\n",
    "# pred = rf.predict(test_vectors)\n",
    "# sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary')\n",
    "# 0.92093023255813955\n",
    "# We see that this classifier achieves a very high F score. The sklearn guide to 20 newsgroups indicates that Multinomial Naive Bayes overfits this dataset by learning irrelevant stuff, such as headers. Let's see if random forests do the same.\n",
    "\n",
    "# Explaining predictions using lime\n",
    "# Lime explainers assume that classifiers act on raw text, but sklearn classifiers act on vectorized representation of texts. For this purpose, we use sklearn's pipeline, and implements predict_proba on raw_text lists.\n",
    "\n",
    "# from lime import lime_text\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# c = make_pipeline(vectorizer, rf)\n",
    "# print(c.predict_proba([newsgroups_test.data[0]]))\n",
    "# [[ 0.274  0.726]]\n",
    "# Now we create an explainer object. We pass the class_names a an argument for prettier display.\n",
    "\n",
    "# from lime.lime_text import LimeTextExplainer\n",
    "# explainer = LimeTextExplainer(class_names=class_names)\n",
    "# We then generate an explanation with at most 6 features for an arbitrary document in the test set.\n",
    "\n",
    "# idx = 83\n",
    "# exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
    "# print('Document id: %d' % idx)\n",
    "# print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
    "# print('True class: %s' % class_names[newsgroups_test.target[idx]])\n",
    "# Document id: 83\n",
    "# Probability(christian) = 0.414\n",
    "# True class: atheism\n",
    "# The classifier got this example right (it predicted atheism).\n",
    "# The explanation is presented below as a list of weighted features.\n",
    "\n",
    "# exp.as_list()\n",
    "# [(u'Posting', -0.15748303818990594),\n",
    "#  (u'Host', -0.13220892468795911),\n",
    "#  (u'NNTP', -0.097422972255878093),\n",
    "#  (u'edu', -0.051080418945152584),\n",
    "#  (u'have', -0.010616558305370854),\n",
    "#  (u'There', -0.0099743822272458232)]\n",
    "# These weighted features are a linear model, which approximates the behaviour of the random forest classifier in the vicinity of the test example. Roughly, if we remove 'Posting' and 'Host' from the document , the prediction should move towards the opposite class (Christianity) by about 0.27 (the sum of the weights for both features). Let's see if this is the case.\n",
    "\n",
    "# print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n",
    "# tmp = test_vectors[idx].copy()\n",
    "# tmp[0,vectorizer.vocabulary_['Posting']] = 0\n",
    "# tmp[0,vectorizer.vocabulary_['Host']] = 0\n",
    "# print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n",
    "# print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])\n",
    "# Original prediction: 0.414\n",
    "# Prediction removing some features: 0.684\n",
    "# Difference: 0.27\n",
    "# Pretty close!\n",
    "# The words that explain the model around this document seem very arbitrary - not much to do with either Christianity or Atheism.\n",
    "# In fact, these are words that appear in the email headers (you will see this clearly soon), which make distinguishing between the classes much easier.\n",
    "\n",
    "# Visualizing explanations\n",
    "# The explanations can be returned as a matplotlib barplot:\n",
    "\n",
    "# %matplotlib inline\n",
    "# fig = exp.as_pyplot_figure()\n",
    "\n",
    "# The explanations can also be exported as an html page (which we can render here in this notebook), using D3.js to render graphs.\n",
    "\n",
    "# exp.show_in_notebook(text=False)\n",
    "# Prediction probabilities\n",
    "# 0.59\n",
    "# atheism\n",
    "# 0.41\n",
    "# christian\n",
    "# atheism\n",
    "# christian\n",
    "# Posting\n",
    "# 0.16\n",
    "# Host\n",
    "# 0.13\n",
    "# NNTP\n",
    "# 0.10\n",
    "# edu\n",
    "# 0.05\n",
    "# have\n",
    "# 0.01\n",
    "# There\n",
    "# 0.01\n",
    "# Alternatively, we can save the fully contained html page to a file:\n",
    "\n",
    "# exp.save_to_file('/tmp/oi.html')\n",
    "# Finally, we can also include a visualization of the original document, with the words in the explanations highlighted. Notice how the words that affect the classifier the most are all in the email header.\n",
    "\n",
    "# exp.show_in_notebook(text=True)\n",
    "# Prediction probabilities\n",
    "# 0.59\n",
    "# atheism\n",
    "# 0.41\n",
    "# christian\n",
    "# atheism\n",
    "# christian\n",
    "# Posting\n",
    "# 0.16\n",
    "# Host\n",
    "# 0.13\n",
    "# NNTP\n",
    "# 0.10\n",
    "# edu\n",
    "# 0.05\n",
    "# have\n",
    "# 0.01\n",
    "# There\n",
    "# 0.01\n",
    "# Text with highlighted words\n",
    "# From: johnchad@triton.unm.edu (jchadwic)\n",
    "# Subject: Another request for Darwin Fish\n",
    "# Organization: University of New Mexico, Albuquerque\n",
    "# Lines: 11\n",
    "# NNTP-Posting-Host: triton.unm.edu\n",
    "\n",
    "# Hello Gang,\n",
    "\n",
    "# There have been some notes recently asking where to obtain the DARWIN fish.\n",
    "# This is the same question I have and I have not seen an answer on the\n",
    "# net. If anyone has a contact please post on the net or email me.\n",
    "\n",
    "# Thanks,\n",
    "\n",
    "# john chadwick\n",
    "# johnchad@triton.unm.edu\n",
    "# or\n",
    "# That's it for this tutorial. Random forests were just an example, this explainer works for any classifier you may want to use, as long as it implements predict_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3fdc95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    order = np.random.permutation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9b715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
